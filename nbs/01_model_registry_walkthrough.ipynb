{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Snowflake Model Registry Walkthrough\n",
        "\n",
        "Exploration of the linear-regression showcase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> We'll work iteratively—looking at code, running a cell, and immediately inspecting the artifacts. Feel free to run cells as we go; each one is designed to be fast and self-contained.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from pprint import pprint\n",
        "\n",
        "import yaml\n",
        "\n",
        "from core import (\n",
        "    pipeline_config_from_mapping,\n",
        "    run_pipeline,\n",
        "    DataConfig,\n",
        "    TrainConfig,\n",
        "    RegistryConfig,\n",
        "    PipelineSteps,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Start with a lightweight config\n",
        "\n",
        "Rather than editing YAML off to the side, we'll build a dictionary in the notebook (fast.ai style) and convert it to the `PipelineConfig` dataclass. This keeps the workflow reproducible and easy to tweak mid-session.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PipelineConfig(data=DataConfig(n_samples=2000, n_features=20, random_state=42, csv_path=PosixPath('notebook_synthetic_data.csv'), upload_to_snowflake=False, connection_name='legalzoom', database='ML_SHOWCASE', data_schema='DATA', table_name='SYNTHETIC_DATA'), train=TrainConfig(test_size=0.2, random_state=42, scaler_path=PosixPath('scaler.pkl'), model_path=PosixPath('model.pkl'), test_data_path=PosixPath('test_data.csv'), metrics_path=PosixPath('model_metrics.json')), registry=RegistryConfig(connection_name='legalzoom', database='ML_SHOWCASE', schema='MODELS', model_name='LINEAR_REGRESSION_CUSTOM', user_files={'preprocessing': ['scaler.pkl']}, conda_dependencies=['snowflake::scikit-learn==1.3.0', 'snowflake::pandas==2.0.3', 'snowflake::numpy==1.24.3'], python_version='3.10', enable_explainability=False, target_platform_mode='WAREHOUSE_ONLY'), steps=PipelineSteps(generate_data=True, train_model=True, verify_pickles=True, log_model=False), serving=ServingConfig(enabled=False, compute_pool=None, service_name=None, min_instances=1, max_instances=1, instance_family='CPU_X64_M'))"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "base_cfg = {\n",
        "    \"data\": {\n",
        "        \"n_samples\": 2000,  # keep things snappy for interactive runs\n",
        "        \"csv_path\": \"notebook_synthetic_data.csv\",\n",
        "        \"upload_to_snowflake\": False,  # disable remote writes while we explore\n",
        "    },\n",
        "    \"steps\": {\n",
        "        \"log_model\": False,  # skip registry logging locally; we'll show how later\n",
        "    },\n",
        "}\n",
        "\n",
        "cfg = pipeline_config_from_mapping(base_cfg)\n",
        "cfg\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Run the local pipeline\n",
        "\n",
        "Notebooks always *do the thing* so we can look at the outputs. Because we disabled Snowflake calls, this cell should complete in a couple of seconds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-11-10 17:51:32 | INFO | core | ================================================================================\n",
            "2025-11-10 17:51:32 | INFO | core | GENERATING SYNTHETIC DATASET\n",
            "2025-11-10 17:51:32 | INFO | core | ================================================================================\n",
            "2025-11-10 17:51:32 | INFO | core | Dataset summary: samples=2,000, features=20\n",
            "2025-11-10 17:51:32 | INFO | core | Target mean=45.09 std=208.06\n",
            "2025-11-10 17:51:32 | INFO | core | ================================================================================\n",
            "2025-11-10 17:51:32 | INFO | core | SAVING DATA TO CSV\n",
            "2025-11-10 17:51:32 | INFO | core | ================================================================================\n",
            "2025-11-10 17:51:32 | INFO | core | Saved data to notebook_synthetic_data.csv (0.79 MB)\n",
            "2025-11-10 17:51:32 | INFO | core | Snowflake upload skipped (upload_to_snowflake=False)\n",
            "2025-11-10 17:51:32 | INFO | core | Split data: train=1,600, test=400 (test_size=20%)\n",
            "2025-11-10 17:51:32 | INFO | custom_model | ================================================================================\n",
            "2025-11-10 17:51:32 | INFO | custom_model | TRAINING MODEL WITH PREPROCESSING\n",
            "2025-11-10 17:51:32 | INFO | custom_model | ================================================================================\n",
            "2025-11-10 17:51:32 | INFO | custom_model | 1. Fitting Custom Z-Scaler...\n",
            "2025-11-10 17:51:32 | INFO | custom_model |    Scaler fitted\n",
            "2025-11-10 17:51:32 | INFO | custom_model |    Features: 20\n",
            "2025-11-10 17:51:32 | INFO | custom_model |    Mean range: [-0.05, 0.05]\n",
            "2025-11-10 17:51:32 | INFO | custom_model |    Std range: [0.94, 1.03]\n",
            "2025-11-10 17:51:32 | INFO | custom_model | 2. Training Linear Regression Model...\n",
            "2025-11-10 17:51:32 | INFO | custom_model |    Model trained\n",
            "2025-11-10 17:51:32 | INFO | custom_model |    Coefficients: 20\n",
            "2025-11-10 17:51:32 | INFO | custom_model |    Intercept: 44.09\n",
            "2025-11-10 17:51:32 | INFO | custom_model | 3. Saving Components as Separate Pickle Files...\n",
            "2025-11-10 17:51:32 | INFO | custom_model |    Saved scaler to: scaler.pkl\n",
            "2025-11-10 17:51:32 | INFO | custom_model |    Saved model to: model.pkl\n",
            "2025-11-10 17:51:32 | INFO | custom_model | Training complete!\n",
            "2025-11-10 17:51:32 | INFO | custom_model |   Components saved as separate pickle files:\n",
            "2025-11-10 17:51:32 | INFO | custom_model |     - scaler.pkl (preprocessing)\n",
            "2025-11-10 17:51:32 | INFO | custom_model |     - model.pkl (model)\n",
            "2025-11-10 17:51:32 | INFO | core | ================================================================================\n",
            "2025-11-10 17:51:32 | INFO | core | EVALUATING MODEL\n",
            "2025-11-10 17:51:32 | INFO | core | ================================================================================\n",
            "2025-11-10 17:51:32 | INFO | core | Train metrics: RMSE=9.9374 MAE=7.9845 R2=0.9978\n",
            "2025-11-10 17:51:32 | INFO | core | Test metrics: RMSE=10.0226 MAE=8.0069 R2=0.9974\n",
            "2025-11-10 17:51:32 | INFO | core | ================================================================================\n",
            "2025-11-10 17:51:32 | INFO | core | SAVING TRAINING ARTIFACTS\n",
            "2025-11-10 17:51:32 | INFO | core | ================================================================================\n",
            "2025-11-10 17:51:32 | INFO | core | Stored test data at test_data.csv\n",
            "2025-11-10 17:51:32 | INFO | core | Stored metrics at model_metrics.json\n",
            "2025-11-10 17:51:32 | INFO | core | ================================================================================\n",
            "2025-11-10 17:51:32 | INFO | core | VERIFYING PICKLE ARTIFACTS\n",
            "2025-11-10 17:51:32 | INFO | core | ================================================================================\n",
            "2025-11-10 17:51:32 | INFO | core | Verified prediction pipeline on 10 samples\n",
            "2025-11-10 17:51:32 | INFO | core | Sample MSE=73.0917\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "dict_keys(['dataframe', 'csv_path', 'table_name', 'metrics', 'verification_passed'])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results = run_pipeline(cfg)\n",
        "results.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now have a pandas DataFrame in memory, metrics persisted to disk, and verified pickles—all without touching Snowflake.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Inspect artifacts\n",
        "\n",
        "Fast.ai notebooks celebrate curiosity—let's peek inside the pieces we just created.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>FEATURE_00</th>\n",
              "      <th>FEATURE_01</th>\n",
              "      <th>FEATURE_02</th>\n",
              "      <th>FEATURE_03</th>\n",
              "      <th>FEATURE_04</th>\n",
              "      <th>FEATURE_05</th>\n",
              "      <th>FEATURE_06</th>\n",
              "      <th>FEATURE_07</th>\n",
              "      <th>FEATURE_08</th>\n",
              "      <th>...</th>\n",
              "      <th>FEATURE_11</th>\n",
              "      <th>FEATURE_12</th>\n",
              "      <th>FEATURE_13</th>\n",
              "      <th>FEATURE_14</th>\n",
              "      <th>FEATURE_15</th>\n",
              "      <th>FEATURE_16</th>\n",
              "      <th>FEATURE_17</th>\n",
              "      <th>FEATURE_18</th>\n",
              "      <th>FEATURE_19</th>\n",
              "      <th>TARGET</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.811768</td>\n",
              "      <td>0.010015</td>\n",
              "      <td>-1.497826</td>\n",
              "      <td>-0.752130</td>\n",
              "      <td>0.286496</td>\n",
              "      <td>-0.469290</td>\n",
              "      <td>0.449818</td>\n",
              "      <td>0.509838</td>\n",
              "      <td>-0.414505</td>\n",
              "      <td>...</td>\n",
              "      <td>1.357600</td>\n",
              "      <td>0.850633</td>\n",
              "      <td>-1.005819</td>\n",
              "      <td>0.220245</td>\n",
              "      <td>-1.172288</td>\n",
              "      <td>-1.520067</td>\n",
              "      <td>0.682041</td>\n",
              "      <td>0.773936</td>\n",
              "      <td>0.741920</td>\n",
              "      <td>-8.431706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.365760</td>\n",
              "      <td>0.518219</td>\n",
              "      <td>-0.179515</td>\n",
              "      <td>-0.393090</td>\n",
              "      <td>-0.954618</td>\n",
              "      <td>0.346117</td>\n",
              "      <td>-1.941568</td>\n",
              "      <td>0.492014</td>\n",
              "      <td>0.158095</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.492462</td>\n",
              "      <td>-0.506189</td>\n",
              "      <td>0.894233</td>\n",
              "      <td>-1.567988</td>\n",
              "      <td>2.064220</td>\n",
              "      <td>-1.001315</td>\n",
              "      <td>-0.766323</td>\n",
              "      <td>-1.710603</td>\n",
              "      <td>-2.384906</td>\n",
              "      <td>-528.622889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>-0.328375</td>\n",
              "      <td>0.409141</td>\n",
              "      <td>-0.874199</td>\n",
              "      <td>-0.587738</td>\n",
              "      <td>0.204798</td>\n",
              "      <td>0.644311</td>\n",
              "      <td>1.107721</td>\n",
              "      <td>0.146476</td>\n",
              "      <td>-0.800590</td>\n",
              "      <td>...</td>\n",
              "      <td>0.638187</td>\n",
              "      <td>1.414841</td>\n",
              "      <td>-0.111847</td>\n",
              "      <td>-1.443201</td>\n",
              "      <td>0.523324</td>\n",
              "      <td>1.744311</td>\n",
              "      <td>-0.452690</td>\n",
              "      <td>1.592025</td>\n",
              "      <td>0.566602</td>\n",
              "      <td>219.172623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>-0.247118</td>\n",
              "      <td>0.855351</td>\n",
              "      <td>0.313623</td>\n",
              "      <td>0.576917</td>\n",
              "      <td>1.620112</td>\n",
              "      <td>-2.406278</td>\n",
              "      <td>1.368677</td>\n",
              "      <td>0.883493</td>\n",
              "      <td>0.859173</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.144827</td>\n",
              "      <td>1.447680</td>\n",
              "      <td>0.039319</td>\n",
              "      <td>1.692713</td>\n",
              "      <td>-1.272305</td>\n",
              "      <td>-0.339397</td>\n",
              "      <td>0.423944</td>\n",
              "      <td>-0.511764</td>\n",
              "      <td>0.365831</td>\n",
              "      <td>403.424173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.985311</td>\n",
              "      <td>-0.531123</td>\n",
              "      <td>-0.055674</td>\n",
              "      <td>0.088560</td>\n",
              "      <td>-0.941764</td>\n",
              "      <td>0.614847</td>\n",
              "      <td>-0.924623</td>\n",
              "      <td>-0.474530</td>\n",
              "      <td>1.862419</td>\n",
              "      <td>...</td>\n",
              "      <td>0.016415</td>\n",
              "      <td>-1.178452</td>\n",
              "      <td>1.090107</td>\n",
              "      <td>0.128195</td>\n",
              "      <td>-0.419826</td>\n",
              "      <td>-1.403840</td>\n",
              "      <td>0.726033</td>\n",
              "      <td>0.070687</td>\n",
              "      <td>-0.456796</td>\n",
              "      <td>-194.605547</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID  FEATURE_00  FEATURE_01  FEATURE_02  FEATURE_03  FEATURE_04  FEATURE_05  \\\n",
              "0   1    0.811768    0.010015   -1.497826   -0.752130    0.286496   -0.469290   \n",
              "1   2    0.365760    0.518219   -0.179515   -0.393090   -0.954618    0.346117   \n",
              "2   3   -0.328375    0.409141   -0.874199   -0.587738    0.204798    0.644311   \n",
              "3   4   -0.247118    0.855351    0.313623    0.576917    1.620112   -2.406278   \n",
              "4   5    0.985311   -0.531123   -0.055674    0.088560   -0.941764    0.614847   \n",
              "\n",
              "   FEATURE_06  FEATURE_07  FEATURE_08  ...  FEATURE_11  FEATURE_12  \\\n",
              "0    0.449818    0.509838   -0.414505  ...    1.357600    0.850633   \n",
              "1   -1.941568    0.492014    0.158095  ...   -1.492462   -0.506189   \n",
              "2    1.107721    0.146476   -0.800590  ...    0.638187    1.414841   \n",
              "3    1.368677    0.883493    0.859173  ...   -0.144827    1.447680   \n",
              "4   -0.924623   -0.474530    1.862419  ...    0.016415   -1.178452   \n",
              "\n",
              "   FEATURE_13  FEATURE_14  FEATURE_15  FEATURE_16  FEATURE_17  FEATURE_18  \\\n",
              "0   -1.005819    0.220245   -1.172288   -1.520067    0.682041    0.773936   \n",
              "1    0.894233   -1.567988    2.064220   -1.001315   -0.766323   -1.710603   \n",
              "2   -0.111847   -1.443201    0.523324    1.744311   -0.452690    1.592025   \n",
              "3    0.039319    1.692713   -1.272305   -0.339397    0.423944   -0.511764   \n",
              "4    1.090107    0.128195   -0.419826   -1.403840    0.726033    0.070687   \n",
              "\n",
              "   FEATURE_19      TARGET  \n",
              "0    0.741920   -8.431706  \n",
              "1   -2.384906 -528.622889  \n",
              "2    0.566602  219.172623  \n",
              "3    0.365831  403.424173  \n",
              "4   -0.456796 -194.605547  \n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results[\"dataframe\"].head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'train': {'mse': 98.7510018487586,\n",
              "  'rmse': 9.937353865529728,\n",
              "  'mae': 7.984539740318553,\n",
              "  'r2': 0.9977743020602813},\n",
              " 'test': {'mse': 100.45261972353805,\n",
              "  'rmse': 10.022605435890313,\n",
              "  'mae': 8.00694078191657,\n",
              "  'r2': 0.9974141111691142}}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metrics_path = cfg.train.metrics_path\n",
        "with metrics_path.open() as fh:\n",
        "    metrics = json.load(fh)\n",
        "\n",
        "metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'test': {'mae': 8.00694078191657,\n",
            "          'mse': 100.45261972353805,\n",
            "          'r2': 0.9974141111691142,\n",
            "          'rmse': 10.022605435890313},\n",
            " 'train': {'mae': 7.984539740318553,\n",
            "           'mse': 98.7510018487586,\n",
            "           'r2': 0.9977743020602813,\n",
            "           'rmse': 9.937353865529728}}\n"
          ]
        }
      ],
      "source": [
        "pprint(metrics)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notice how the RMSE and MAE line up with the numbers we logged earlier—they come straight out of the shared `core.py` utilities, so the notebook and CLI stay perfectly in sync.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Taking it all the way to Snowflake\n",
        "\n",
        "When you're ready to promote the run, flip the switches that we disabled earlier. Here's the minimum set of changes:\n",
        "\n",
        "1. Set `base_cfg[\"data\"][\"upload_to_snowflake\"] = True`\n",
        "2. Set `base_cfg[\"steps\"][\"log_model\"] = True`\n",
        "3. (Optional) Toggle `cfg.serving.enabled = True` and fill in `compute_pool` if you want SPCS deployment.\n",
        "\n",
        "You can do this directly in the notebook (just re-run the config cell) or export the dict to `pipeline.yml` for the CLI tools.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Uncomment the following lines when you're ready to push a real model to Snowflake.\n",
        "base_cfg[\"data\"][\"upload_to_snowflake\"] = True\n",
        "base_cfg[\"steps\"][\"log_model\"] = True\n",
        "cfg = pipeline_config_from_mapping(base_cfg)\n",
        "run_pipeline(cfg)\n",
        "\n",
        "print(\"Snowflake deployment is opt-in—flip the switches above when you're ready.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "**Next steps**\n",
        "- Pair this notebook with `run_pipeline.py --summary` to compare outputs.\n",
        "- Use the generated artifacts (`notebook_synthetic_data.csv`, `scaler.pkl`, etc.) as fixtures in integration tests.\n",
        "- Drop into `deploy_service.py` once you're comfortable with the Snowflake flow and want an interactive SPCS deployment walkthrough.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "legalzoom-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
